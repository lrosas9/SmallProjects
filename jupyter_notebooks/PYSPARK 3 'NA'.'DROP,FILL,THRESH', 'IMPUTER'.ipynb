{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f943a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18173f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe = spark.read.option('Header','true').csv('test2.csv').show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0604489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edgar</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flaco</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rojas</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amlo</td>\n",
       "      <td>56.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adame</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name   Age  Experience   Salary\n",
       "0  Edgar  31.0        12.0  30000.0\n",
       "1  Flaco  21.0         3.0  50000.0\n",
       "2  Rojas  54.0         4.0  40000.0\n",
       "3   Amlo  56.0        23.0  60000.0\n",
       "4  Adame   NaN         NaN  55000.0\n",
       "5    NaN  78.0         2.0     21.0\n",
       "6    NaN   9.0         NaN      NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58d2e01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "| Name| Age|Experience|Salary|\n",
      "+-----+----+----------+------+\n",
      "|Edgar|  31|        12| 30000|\n",
      "|Flaco|  21|         3| 50000|\n",
      "|Rojas|  54|         4| 40000|\n",
      "| Amlo|  56|        23| 60000|\n",
      "|Adame|null|      null| 55000|\n",
      "| null|  78|         2|    21|\n",
      "| null|   9|      null|  null|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#spark.read.option('Header','true').csv('test2.csv').show()\n",
    "##import pandas as pd\n",
    "##pd.read_csv('test2.csv')\n",
    "dframe = spark.read.csv('test2.csv', header=True, inferSchema=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e350a183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------------------+----------------+------------------+\n",
      "|summary| Name|               Age|      Experience|            Salary|\n",
      "+-------+-----+------------------+----------------+------------------+\n",
      "|  count|    5|                 6|               5|                 6|\n",
      "|   mean| null|              41.5|             8.8|39170.166666666664|\n",
      "| stddev| null|25.633961847517835|8.87130204648675| 21996.31196738823|\n",
      "|    min|Adame|                21|              12|                21|\n",
      "|    max|Rojas|                 9|               4|             60000|\n",
      "+-------+-----+------------------+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dframe.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b3254ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dad7d89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| Age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  31|        12| 30000|\n",
      "|  21|         3| 50000|\n",
      "|  54|         4| 40000|\n",
      "|  56|        23| 60000|\n",
      "|null|      null| 55000|\n",
      "|  78|         2|    21|\n",
      "|   9|      null|  null|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dframe.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d7b74bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "| Name| Age|Experience|Salary|\n",
      "+-----+----+----------+------+\n",
      "|Edgar|  31|        12| 30000|\n",
      "|Flaco|  21|         3| 50000|\n",
      "|Rojas|  54|         4| 40000|\n",
      "| Amlo|  56|        23| 60000|\n",
      "|Adame|null|      null| 55000|\n",
      "| null|  78|         2|    21|\n",
      "| null|   9|      null|  null|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86e11c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|Age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Edgar| 31|        12| 30000|\n",
      "|Flaco| 21|         3| 50000|\n",
      "|Rojas| 54|         4| 40000|\n",
      "| Amlo| 56|        23| 60000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dframe.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "786d6c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "| Name| Age|Experience|Salary|\n",
      "+-----+----+----------+------+\n",
      "|Edgar|  31|        12| 30000|\n",
      "|Flaco|  21|         3| 50000|\n",
      "|Rojas|  54|         4| 40000|\n",
      "| Amlo|  56|        23| 60000|\n",
      "|Adame|null|      null| 55000|\n",
      "| null|  78|         2|    21|\n",
      "| null|   9|      null|  null|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dframe.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14ee4994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|Age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Edgar| 31|        12| 30000|\n",
      "|Flaco| 21|         3| 50000|\n",
      "|Rojas| 54|         4| 40000|\n",
      "| Amlo| 56|        23| 60000|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dframe.na.drop(how=\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6790e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+\n",
      "| Name| Age|Experience|Salary|\n",
      "+-----+----+----------+------+\n",
      "|Edgar|  31|        12| 30000|\n",
      "|Flaco|  21|         3| 50000|\n",
      "|Rojas|  54|         4| 40000|\n",
      "| Amlo|  56|        23| 60000|\n",
      "|Adame|null|      null| 55000|\n",
      "| null|  78|         2|    21|\n",
      "+-----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dframe.na.drop(how=\"any\",thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0049ab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|Age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Edgar| 31|        12| 30000|\n",
      "|Flaco| 21|         3| 50000|\n",
      "|Rojas| 54|         4| 40000|\n",
      "| Amlo| 56|        23| 60000|\n",
      "| null| 78|         2|    21|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dframe.na.drop(how=\"any\",subset=['Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6b33bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-------------+------+\n",
      "| Name| Age|   Experience|Salary|\n",
      "+-----+----+-------------+------+\n",
      "|Edgar|  31|           12| 30000|\n",
      "|Flaco|  21|            3| 50000|\n",
      "|Rojas|  54|            4| 40000|\n",
      "| Amlo|  56|           23| 60000|\n",
      "|Adame|null|Missing Value| 55000|\n",
      "| null|  78|            2|    21|\n",
      "| null|   9|Missing Value|  null|\n",
      "+-----+----+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dframe.na.fill('Missing Value', 'Experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf6fd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age', 'Experience', 'Salary'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['Age', 'Experience', 'Salary']]\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8260c5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------+-----------+------------------+--------------+\n",
      "| Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+-----+----+----------+------+-----------+------------------+--------------+\n",
      "|Edgar|  31|        12| 30000|         31|                12|         30000|\n",
      "|Flaco|  21|         3| 50000|         21|                 3|         50000|\n",
      "|Rojas|  54|         4| 40000|         54|                 4|         40000|\n",
      "| Amlo|  56|        23| 60000|         56|                23|         60000|\n",
      "|Adame|null|      null| 55000|         41|                 8|         55000|\n",
      "| null|  78|         2|    21|         78|                 2|            21|\n",
      "| null|   9|      null|  null|          9|                 8|         39170|\n",
      "+-----+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add imputation cols to dframe\n",
    "imputer.fit(dframe).transform(dframe).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c8c4a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34d61465",
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe = spark.read.csv('test2.csv', header=True, inferSchema=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
